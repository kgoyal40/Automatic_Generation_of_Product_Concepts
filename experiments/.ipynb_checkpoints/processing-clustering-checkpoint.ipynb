{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.core import *\n",
    "from src.exps import *\n",
    "from src.io import *\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTERING_TARGET_DIR = Path(\".\").absolute() / \"clustering\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_contexts_names, all_contexts = get_filtered_clusters()\n",
    "context_overview = pd.read_csv(CONTEXT_NAMES_FP)\n",
    "context_overview = context_overview[context_overview['mc_id'].isin([int(n) for n in all_contexts_names])]\n",
    "context_overview['# songs'] = [len(all_contexts['000000{}'.format(c)]) for c in context_overview['mc_id']]\n",
    "context_overview = context_overview[context_overview['# songs'] > 100]\n",
    "context_overview.reset_index(inplace=True, drop=True)\n",
    "context_overview['# subcontexts'] = [get_subcontext_count('000000{}'.format(c)) \n",
    "                                     for c in context_overview.mc_id]\n",
    "context_overview.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "context_overview[context_overview['# songs'] > 5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(CLUSTERING_TARGET_DIR/ 'results_clustering_0906.txt','r') as f:\n",
    "    results_clustering = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_clustering = [r[:-1].split(',') for r in results_clustering]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results_clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_clustering_processed = []\n",
    "for r in results_clustering:\n",
    "    processed = [float(r[i]) if i not in [3, 7] else r[i][1:] for i in range(len(r))]\n",
    "    results_clustering_processed.append(processed)\n",
    "results_clustering_processed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_clustering_processed = pd.DataFrame(results_clustering_processed)\n",
    "results_clustering_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_clustering_processed.columns = ['# experiment', '# learned context', 'source context', 'reliable negative method',\n",
    "                              'discard threshold', 'rocchio threshold', '# songs target', 'query type', '# songs predicted', \n",
    "                              'recall', 'precision', 'f1-score']\n",
    "results_clustering_processed = results_clustering_processed[results_clustering_processed['rocchio threshold'] == 0]\n",
    "results_clustering_processed.reset_index(inplace=True, drop=True)\n",
    "results_clustering_processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(1, 11):\n",
    "    contexts = len(np.unique(results_clustering_processed[(results_clustering_processed['# experiment'] == i)]['# learned context']))\n",
    "    for j in range(1, contexts + 1):\n",
    "        sources = np.unique(results_clustering_processed[(results_clustering_processed['# experiment'] == i) & \n",
    "                                     (results_clustering_processed['# learned context'] == j)]['source context'])\n",
    "        if len(sources) < 40:\n",
    "            print(i, j, len(sources))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "overview = pd.DataFrame()\n",
    "for n in set(results_clustering_processed['# experiment']):\n",
    "    for e in set(results_clustering_processed[(results_clustering_processed['# experiment'] == n)]['# learned context']):\n",
    "        for reliable_negative_method in ['r', 'l']:\n",
    "            for t in [0, 0.1, 0.2]:\n",
    "                for q in ['dt-query', 'songs-query']:\n",
    "                    subset = results_clustering_processed[(results_clustering_processed['# experiment'] == n) & \n",
    "                                                          (results_clustering_processed['# learned context'] == e) & \n",
    "                                                          (results_clustering_processed['reliable negative method'] == reliable_negative_method) &\n",
    "                                                          (results_clustering_processed['discard threshold'] == t) & \n",
    "                                                          (results_clustering_processed['query type'] == q)]\n",
    "                    subset.reset_index(inplace=True, drop=True)\n",
    "                    if subset.shape[0] > 0:\n",
    "                        max_index = subset[\"f1-score\"].idxmax()\n",
    "                        if math.isnan(max_index):\n",
    "                            subset = subset.iloc[0, :]\n",
    "                        else:\n",
    "                            subset = subset.iloc[max_index, :]\n",
    "                        overview = overview.append(subset)\n",
    "overview.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "overview.shape, 10*40*40*6*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "overlap_scores = pd.DataFrame()\n",
    "for threshold in [0, 0.1, 0.2]:\n",
    "    for q in ['dt-query', 'songs-query']:\n",
    "        for r in ['r', 'l']:\n",
    "            data = overview[(overview['discard threshold'] == threshold) & \n",
    "                            (overview['query type'] == q) &\n",
    "                            (overview['reliable negative method'] == r)]\n",
    "            s = data[data['f1-score'] >= 0.7].shape[0]/data.shape[0]\n",
    "            overlap_scores = overlap_scores.append([[q, r, threshold, data.shape[0], s]])\n",
    "\n",
    "overlap_scores.columns = ['query type', 'reliable negative approach', 'discard threshold', '# learned contexts', 'score']\n",
    "overlap_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def big_chart(chart, fontsize = 20): \n",
    "    return chart.configure_axis(\n",
    "        grid = True, \n",
    "    labelFontSize = fontsize,\n",
    "    titleFontSize = fontsize\n",
    ").configure_title(\n",
    "    fontSize = fontsize\n",
    "    ).configure_legend(\n",
    "titleFontSize=fontsize,\n",
    "labelFontSize=fontsize\n",
    ").configure_view(\n",
    "    strokeWidth=0\n",
    ")\n",
    "\n",
    "def small_chart(chart, fontsize=None): \n",
    "    return big_chart(chart.properties(width=150,\n",
    "                             height=150\n",
    "                            ), fontsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_DIR = str(Path().absolute() / 'plots-clustering')\n",
    "\n",
    "data = overlap_scores[overlap_scores['query type'] == 'dt-query']\n",
    "chart_d = alt.Chart(data).mark_bar().encode(\n",
    "    alt.X(\"reliable negative approach\", title=None),\n",
    "    alt.Y('score', title='overlap accuracy'),\n",
    "    alt.Color('reliable negative approach', scale=alt.Scale(scheme='tableau10'), title = 'Rel. Neg.'), \n",
    "    alt.Column('discard threshold', header=alt.Header(titleFontSize=20, labelFontSize=20))\n",
    ")\n",
    "big_chart(chart_d, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = overlap_scores[overlap_scores['query type'] == 'songs-query']\n",
    "chart_s = alt.Chart(data).mark_bar().encode(\n",
    "    alt.X(\"reliable negative approach\", title=None),\n",
    "    alt.Y('score', title='overlap accuracy'),\n",
    "    alt.Color('reliable negative approach', scale=alt.Scale(scheme='tableau10'), title = 'Rel. Neg.'), \n",
    "    alt.Column('discard threshold', header=alt.Header(titleFontSize=20, labelFontSize=20))\n",
    ")\n",
    "big_chart(chart_s, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "from altair_saver import save\n",
    "PLOT_DIR = str(Path().absolute() / 'plots-clustering')\n",
    "\n",
    "for threshold in [0, 0.1, 0.2]:\n",
    "    for q in ['dt-query', 'songs-query']:\n",
    "        for r in ['r', 'l']:\n",
    "            data = overview[(overview['discard threshold'] == threshold) & \n",
    "                            (overview['query type'] == q) &\n",
    "                            (overview['reliable negative method'] == r)]\n",
    "            if data.shape[0] > 0:\n",
    "                chart_hist = alt.Chart(data).mark_bar().encode(\n",
    "                                                        alt.X(\"f1-score:Q\", bin=True),\n",
    "                                                        alt.Y('count()', title='Count')\n",
    "                                                    )\n",
    "                save(big_chart(chart_hist, fontsize=20), '{}/f1_score_query_{}_discard_{}_rel_{}.png'.format(PLOT_DIR, q, threshold, r), scale_factor=2.0)\n",
    "        \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
